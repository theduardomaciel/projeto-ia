# ü§ñ Provedores de LLM - Guia de Configura√ß√£o

## Provedores Suportados

O sistema suporta **3 provedores gratuitos e acess√≠veis**:

### 1. **Google Gemini** (Recomendado)
- ‚úÖ **Totalmente gratuito**
- ‚úÖ Rate limit generoso (~60 requests/minuto)
- ‚úÖ Modelos de alta qualidade
- ‚úÖ F√°cil configura√ß√£o

**Como obter:**
1. Acesse: https://aistudio.google.com/app/apikey
2. Fa√ßa login com conta Google
3. Clique em "Get API Key" ‚Üí "Create API Key"
4. Copie e adicione ao `.env`: `GEMINI_API_KEY=sua_chave_aqui`

**Modelos dispon√≠veis:**
- `gemini-1.5-flash` (padr√£o) - r√°pido e eficiente
- `gemini-1.5-pro` - mais poderoso, melhor para tarefas complexas
- `gemini-2.0-flash-exp` - experimental, mais recente

---

### 2. **Groq** (Agregador)
- ‚úÖ **Gratuito** (tier inicial)
- ‚úÖ **Muito r√°pido** (infer√™ncia otimizada)
- ‚úÖ M√∫ltiplos modelos open-source
- ‚ö†Ô∏è Rate limits menores que Gemini

**Como obter:**
1. Acesse: https://console.groq.com/keys
2. Crie uma conta (email ou GitHub)
3. V√° em "API Keys" ‚Üí "Create API Key"
4. Copie e adicione ao `.env`: `GROQ_API_KEY=sua_chave_aqui`

**Modelos dispon√≠veis:**
- `llama-3.1-70b-versatile` (padr√£o) - melhor custo-benef√≠cio
- `llama-3.1-8b-instant` - mais r√°pido
- `mixtral-8x7b-32768` - contexto longo
- `gemma-7b-it` - menor, mais r√°pido

**Rate limits (tier gratuito):**
- ~30 requests/minuto
- ~6.000 tokens/minuto

---

### 3. **OpenRouter** (Agregador)
- ‚úÖ Tier gratuito dispon√≠vel
- ‚úÖ Acesso a m√∫ltiplos modelos
- ‚úÖ Fallback autom√°tico entre modelos
- ‚ö†Ô∏è Modelos gratuitos t√™m rate limits

**Como obter:**
1. Acesse: https://openrouter.ai/keys
2. Crie uma conta
3. V√° em "Keys" ‚Üí "Create Key"
4. Copie e adicione ao `.env`: `OPENROUTER_API_KEY=sua_chave_aqui`

**Modelos gratuitos dispon√≠veis:**
- `google/gemma-2-9b-it:free` (padr√£o)
- `meta-llama/llama-3-8b-instruct:free`
- `mistralai/mistral-7b-instruct:free`
- `huggingfaceh4/zephyr-7b-beta:free`

**Rate limits (tier gratuito):**
- Varia por modelo (~10-20 requests/minuto)
- Tokens limitados por dia

---

## Compara√ß√£o de Provedores

| Provedor | Gratuito | Velocidade | Qualidade | Rate Limit | Recomenda√ß√£o |
|----------|----------|-----------|-----------|------------|--------------|
| **Gemini** | ‚úÖ Sim | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Alto | ‚úÖ **Primeira escolha** |
| **Groq** | ‚úÖ Sim | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | M√©dio | ‚úÖ √ìtimo para produ√ß√£o |
| **OpenRouter** | ‚úÖ Sim* | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Baixo | ‚ö†Ô∏è Backup/testes |

*Modelos espec√≠ficos gratuitos, com limita√ß√µes

---

## Configura√ß√£o Recomendada

### Para Desenvolvimento (Uso Intenso)

```env
# Configure m√∫ltiplos provedores para fallback
GEMINI_API_KEY=sua_chave_gemini
GROQ_API_KEY=sua_chave_groq
OPENROUTER_API_KEY=sua_chave_openrouter

DEFAULT_LLM_PROVIDER=gemini
```

### Para Produ√ß√£o (Alta Velocidade)

```env
# Priorize Groq para infer√™ncia r√°pida
GROQ_API_KEY=sua_chave_groq
GEMINI_API_KEY=sua_chave_gemini  # Fallback

DEFAULT_LLM_PROVIDER=groq
```

### Para Testes (M√≠nimo)

```env
# Apenas Gemini √© suficiente
GEMINI_API_KEY=sua_chave_gemini
DEFAULT_LLM_PROVIDER=gemini
```

---

## Uso no C√≥digo

### Provedor Padr√£o (Autom√°tico)

```python
from src.llm.client import get_default_llm

# Usa provedor configurado em DEFAULT_LLM_PROVIDER
# Com fallback autom√°tico se falhar
llm = get_default_llm()
response = llm.call("Seu prompt aqui")
```

### Provedor Espec√≠fico

```python
from src.llm.client import LLMFactory

# For√ßa uso do Gemini
llm = LLMFactory.create("gemini")

# For√ßa uso do Groq com modelo espec√≠fico
llm = LLMFactory.create("groq", model="llama-3.1-8b-instant")

# For√ßa uso do OpenRouter
llm = LLMFactory.create("openrouter", model="meta-llama/llama-3-8b-instruct:free")
```

### Compara√ß√£o Entre Provedores

```python
from src.llm.client import LLMFactory

prompt = "Explique CI/CD em 2 frases"

for provider in ["gemini", "groq", "openrouter"]:
    try:
        llm = LLMFactory.create(provider)
        response = llm.call(prompt, max_tokens=200)
        
        print(f"{provider}: {response.content}")
        print(f"  Lat√™ncia: {response.latency:.2f}s")
        print(f"  Tokens: {response.tokens_used}")
    except Exception as e:
        print(f"{provider}: Erro - {e}")
```

---

## Troubleshooting

### Erro: "API key n√£o encontrada"
- Verifique se o arquivo `.env` existe e est√° na raiz do projeto
- Confirme que a vari√°vel est√° escrita corretamente (ex: `GEMINI_API_KEY`)
- N√£o deixe espa√ßos: `GEMINI_API_KEY=suachave` ‚úÖ vs `GEMINI_API_KEY = suachave` ‚ùå

### Erro: "Rate limit exceeded"
- **Gemini**: Aguarde ~1 minuto (60 req/min)
- **Groq**: Aguarde ~2 minutos (30 req/min)
- **Solu√ß√£o**: Configure m√∫ltiplos provedores para fallback autom√°tico

### Erro: "Model not found"
- Verifique se o modelo est√° dispon√≠vel no tier gratuito
- Groq: use modelos listados acima
- OpenRouter: use apenas modelos com `:free`

### Resposta muito lenta
- **Gemini**: Normal, ~1-3s
- **Groq**: Deve ser <1s (mais r√°pido)
- **OpenRouter**: Varia, ~2-5s
- **Solu√ß√£o**: Priorize Groq para velocidade

---

## Migra√ß√£o de Provedores Antigos

Se voc√™ estava usando **DeepSeek** ou **Grok (xAI)**:

### DeepSeek ‚Üí Groq
```diff
- DEEPSEEK_API_KEY=...
- DEFAULT_LLM_PROVIDER=deepseek
+ GROQ_API_KEY=...
+ DEFAULT_LLM_PROVIDER=groq
```

### Grok (xAI) ‚Üí OpenRouter
```diff
- GROK_API_KEY=...
- DEFAULT_LLM_PROVIDER=grok
+ OPENROUTER_API_KEY=...
+ DEFAULT_LLM_PROVIDER=openrouter
```

**Motivo da mudan√ßa:**
- DeepSeek: Acesso gratuito descontinuado/limitado
- Grok (xAI): Sem tier gratuito acess√≠vel no momento
- Groq/OpenRouter: Alternativas gratuitas e est√°veis

---

## Recomenda√ß√µes para o Projeto Acad√™mico

### 1. Configure pelo menos 2 provedores
```env
GEMINI_API_KEY=...
GROQ_API_KEY=...
```

**Por qu√™?**
- Compara√ß√£o de respostas (requisito do relat√≥rio)
- Resili√™ncia se um provedor cair
- Bypass de rate limits

### 2. Use Gemini como padr√£o
```env
DEFAULT_LLM_PROVIDER=gemini
```

**Por qu√™?**
- Melhor qualidade geral
- Rate limits mais generosos
- Gratuito sem preocupa√ß√µes

### 3. Documente as diferen√ßas
Para o relat√≥rio, compare:
- Qualidade das respostas (soft skills, justificativas)
- Velocidade de infer√™ncia
- Rate limits atingidos
- Facilidade de configura√ß√£o

---

## Recursos Adicionais

- **Gemini Docs**: https://ai.google.dev/docs
- **Groq Docs**: https://console.groq.com/docs
- **OpenRouter Docs**: https://openrouter.ai/docs
- **C√≥digo de exemplo**: `src/llm/examples.py`
- **Valida√ß√£o de setup**: `python validate_setup.py`
